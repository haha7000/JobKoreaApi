"""ì¡ì½”ë¦¬ì•„ ìŠ¤í¬ë˜í¼ ë©”ì¸ í´ë˜ìŠ¤"""
import json
import time
from pathlib import Path
from typing import List, Dict

from src.config import JobKoreaConfig
from src.payload_manager import PayloadManager
from src.api_client import JobKoreaAPIClient
from src.parser import PersonDataParser
from src.exporter import ExcelExporter


class JobKoreaScraper:
    """ì¡ì½”ë¦¬ì•„ ì¸ì¬ ê²€ìƒ‰ ìŠ¤í¬ë˜í¼ ë©”ì¸ í´ë˜ìŠ¤"""

    def __init__(
        self,
        config: JobKoreaConfig,
        payload_manager: PayloadManager,
        output_dir: str = "."
    ):
        self.config = config
        self.api_client = JobKoreaAPIClient(config, payload_manager)
        self.parser = PersonDataParser(config.BASE_URL)
        self.exporter = ExcelExporter()
        self.output_dir = Path(output_dir)

    def scrape(
        self,
        start_page: int = 1,
        end_page: int = 1,
        page_size: int = 10,
        delay: float = 1.0,
        **search_options
    ) -> List[Dict[str, str]]:

        """
        ì¸ì¬ ê²€ìƒ‰ ë° ë°ì´í„° ìˆ˜ì§‘

        Args:
            start_page: ì‹œì‘ í˜ì´ì§€
            end_page: ì¢…ë£Œ í˜ì´ì§€
            page_size: í˜ì´ì§€ë‹¹ ê²°ê³¼ ìˆ˜
            delay: í˜ì´ì§€ ê°„ ì§€ì—° ì‹œê°„(ì´ˆ)
            **search_options: ê²€ìƒ‰ ì˜µì…˜ (job_name, areas, education)
        """
        all_people = []
        current_index = 1  # ì „ì²´ ëˆ„ì  ë²ˆí˜¸
        saveno = 0  # ğŸ”¥ ê²€ìƒ‰ ì„¸ì…˜ ID (1í˜ì´ì§€ëŠ” 0, 2í˜ì´ì§€ë¶€í„° í•„ìš”)

        for page in range(start_page, end_page + 1):
            # saveno í¬í•¨í•˜ì—¬ ê²€ìƒ‰
            response = self.api_client.search(page, page_size, saveno=saveno, **search_options)

            if "application/json" in response.headers.get("Content-Type", ""):
                self._save_json(response.json(), page)
            else:
                # ğŸ”¥ HTMLì—ì„œ saveNo ì¶”ì¶œ (ë‹¤ìŒ í˜ì´ì§€ ìš”ì²­ìš©)
                from bs4 import BeautifulSoup
                soup = BeautifulSoup(response.text, 'html.parser')
                saveno_elem = soup.select_one('input#saveNo')
                if saveno_elem and saveno_elem.get('value'):
                    saveno = int(saveno_elem.get('value'))
                    print(f"ğŸ“Œ saveNo ì¶”ì¶œ: {saveno}")

                # ë°ì´í„° íŒŒì‹±
                people = self._process_html(response.text, page, start_index=current_index)
                all_people.extend(people)
                current_index += len(people)  # ë‹¤ìŒ í˜ì´ì§€ ì‹œì‘ ë²ˆí˜¸

            if page < end_page:
                time.sleep(delay)

        return all_people

    def _save_json(self, data: dict, page: int):
        """JSON ì‘ë‹µ ì €ì¥"""
        filepath = self.output_dir / f"result_page{page}.json"
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"âœ… {filepath} ì €ì¥ ì™„ë£Œ")

    def _process_html(self, html: str, page: int, start_index: int = 1) -> List[Dict[str, str]]:
        """HTML ì‘ë‹µ ì²˜ë¦¬ ë° ì €ì¥"""
        # HTML íŒŒì¼ ì €ì¥
        html_filepath = self.output_dir / f"result_page{page}.html"
        with open(html_filepath, "w", encoding="utf-8") as f:
            f.write(html)

        # ë°ì´í„° íŒŒì‹± (ì‹œì‘ ë²ˆí˜¸ ì „ë‹¬)
        people = self.parser.parse_html(html, start_index=start_index)
        print(f"âœ… {len(people)}ëª… íŒŒì‹± ì™„ë£Œ (page {page}, ë²ˆí˜¸ {start_index}~{start_index+len(people)-1})")

        return people

    def save_results(self, people: List[Dict[str, str]]):
        """ìˆ˜ì§‘í•œ ë°ì´í„° ì €ì¥ (JSON + Excel)"""
        if not people:
            print("âš ï¸  ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"\nì´ {len(people)}ëª… ìˆ˜ì§‘ë¨")

        # JSON ì €ì¥
        json_filepath = self.output_dir / "people_summary.json"
        with open(json_filepath, "w", encoding="utf-8") as f:
            json.dump(people, f, ensure_ascii=False, indent=2)

        # ì—‘ì…€ ì €ì¥
        excel_filepath = self.output_dir / "ë°±ì—”ë“œê°œë°œì_ê²€ìƒ‰ê²°ê³¼.xlsx"
        self.exporter.save(people, str(excel_filepath))
