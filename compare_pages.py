"""1í˜ì´ì§€, 2í˜ì´ì§€, 4í˜ì´ì§€ payload ë¹„êµ"""
import re
import json
import urllib.parse

def extract_payload_from_curl(file_path):
    """cURL íŒŒì¼ì—ì„œ searchCondition payload ì¶”ì¶œ"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # --data-raw 'searchCondition=...' ë¶€ë¶„ ì°¾ê¸°
    match = re.search(r'searchCondition=([^\s\'\"]+)', content)
    if match:
        encoded = match.group(1)
        decoded = urllib.parse.unquote(encoded)
        return json.loads(decoded)
    return None

# ê° í˜ì´ì§€ payload ì¶”ì¶œ
page1 = extract_payload_from_curl('detailsearchajaxCurl/detailsearchajax1Page.txt')
page2 = extract_payload_from_curl('detailsearchajaxCurl/detailsearchajax2Page.txt')
page4 = extract_payload_from_curl('detailsearchajaxCurl/detailsearchajax4Page.txt')

print("="*80)
print("ğŸ“Š 1í˜ì´ì§€, 2í˜ì´ì§€, 4í˜ì´ì§€ Payload ë¹„êµ")
print("="*80)

# ê¸°ë³¸ ì •ë³´ ë¹„êµ
print("\nğŸ” í•µì‹¬ í•„ë“œ ë¹„êµ:")
print(f"{'í•„ë“œ':<15} {'1í˜ì´ì§€':<20} {'2í˜ì´ì§€':<20} {'4í˜ì´ì§€':<20}")
print("-"*80)

fields = ['p', 'ps', 'saveno', 'sf', 'ff', 'savectgrcode']
for field in fields:
    v1 = page1.get(field, 'N/A')
    v2 = page2.get(field, 'N/A')
    v4 = page4.get(field, 'N/A')
    print(f"{field:<15} {str(v1):<20} {str(v2):<20} {str(v4):<20}")

# ì°¨ì´ì  ì°¾ê¸°
print("\n"+"="*80)
print("ğŸ”¥ ì°¨ì´ì  ë¶„ì„")
print("="*80)

all_keys = set(page1.keys()) | set(page2.keys()) | set(page4.keys())
diff_fields = []

for key in sorted(all_keys):
    v1 = page1.get(key)
    v2 = page2.get(key)
    v4 = page4.get(key)

    if not (v1 == v2 == v4):
        diff_fields.append(key)
        print(f"\n[{key}]")
        print(f"  1í˜ì´ì§€: {v1}")
        print(f"  2í˜ì´ì§€: {v2}")
        print(f"  4í˜ì´ì§€: {v4}")

if not diff_fields:
    print("\nì°¨ì´ì  ì—†ìŒ!")
else:
    print(f"\nì´ {len(diff_fields)}ê°œ í•„ë“œê°€ ë‹¤ë¦…ë‹ˆë‹¤: {diff_fields}")

print("\n"+"="*80)
