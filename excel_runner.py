"""ì—‘ì…€ ì„¤ì • íŒŒì¼ì„ ì½ì–´ì„œ ì‹¤í–‰í•˜ëŠ” ë©”ì¸ íŒŒì¼"""
import pandas as pd
from pathlib import Path
from src.config import JobKoreaConfig
from src.payload_manager import PayloadManager
from src.scraper import JobKoreaScraper


def parse_age(age_str):
    """ë‚˜ì´ ë¬¸ìì—´ íŒŒì‹±"""
    if pd.isna(age_str) or str(age_str).strip() == '':
        return None

    age_str = str(age_str).strip()

    # ë²”ìœ„: "26~60" ë˜ëŠ” "26-35"
    if '~' in age_str:
        parts = age_str.split('~')
        return (int(parts[0]), int(parts[1]))
    elif '-' in age_str:
        parts = age_str.split('-')
        return (int(parts[0]), int(parts[1]))

    # ë‹¨ì¼: "28"
    return int(age_str)


def parse_list(value_str):
    """ì½¤ë§ˆë¡œ êµ¬ë¶„ëœ ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    if pd.isna(value_str) or str(value_str).strip() == '':
        return None

    return [x.strip() for x in str(value_str).split(',') if x.strip()]


def parse_area(area_str):
    """ì§€ì—­ ë¬¸ìì—´ íŒŒì‹± (ì˜ˆ: 'ì„œìš¸ì „ì§€ì—­' â†’ ['ì„œìš¸'])"""
    if pd.isna(area_str) or str(area_str).strip() == '':
        return None

    area_str = str(area_str).strip()

    # "ì„œìš¸ì „ì§€ì—­" â†’ "ì„œìš¸"
    if 'ì „ì§€ì—­' in area_str:
        area_str = area_str.replace('ì „ì§€ì—­', '')

    # ì½¤ë§ˆë¡œ êµ¬ë¶„ëœ ê²½ìš°
    if ',' in area_str:
        return [x.strip().replace('ì „ì§€ì—­', '') for x in area_str.split(',') if x.strip()]

    return [area_str]


def load_configs_from_excel(excel_path: str, sheet_name: str):
    """
    jobkorea_Excel.xlsxì˜ 'ê²€ìƒ‰ì¡°ê±´' ì‹œíŠ¸ì—ì„œ ì„¤ì • ë¡œë“œ

    í˜•ì‹:
    - ëª¨ë“  í–‰ì˜ ì§ë¬´ë¥¼ í•˜ë‚˜ì˜ ê²€ìƒ‰ ì¡°ê±´ìœ¼ë¡œ í†µí•©
    - ëª¨ë“  í–‰ì˜ í•„í„° ê°’ë“¤ì„ ìˆ˜ì§‘ (OR ì¡°ê±´)
    """
    df = pd.read_excel(excel_path, sheet_name=sheet_name)

    if len(df) == 0:
        return None

    # ëª¨ë“  í–‰ì—ì„œ í•„í„° ê°’ë“¤ ìˆ˜ì§‘
    all_job_names = []
    categories = []
    all_areas = []
    all_education = []
    all_ages = []
    all_job_status = []

    for idx, row in df.iterrows():
        # ëŒ€ë¶„ë¥˜ ìˆ˜ì§‘
        if pd.notna(row.get('ëŒ€ë¶„ë¥˜')):
            category = str(row['ëŒ€ë¶„ë¥˜']).strip()
            if category:
                categories.append(category)

        # ì§€ì—­ ìˆ˜ì§‘
        if 'ì§€ì—­' in df.columns and pd.notna(row['ì§€ì—­']):
            areas = parse_area(row['ì§€ì—­'])
            if areas:
                all_areas.extend(areas)

        # í•™ë ¥ ìˆ˜ì§‘
        if 'í•™ë ¥' in df.columns and pd.notna(row['í•™ë ¥']):
            edu = str(row['í•™ë ¥']).strip()
            if edu and edu not in all_education:
                all_education.append(edu)

        # ë‚˜ì´ ìˆ˜ì§‘ (ì²« ë²ˆì§¸ ìœ íš¨í•œ ê°’ë§Œ ì‚¬ìš© - ë²”ìœ„ëŠ” í•˜ë‚˜ë§Œ ê°€ëŠ¥)
        if 'ë‚˜ì´' in df.columns and pd.notna(row['ë‚˜ì´']) and not all_ages:
            age = parse_age(row['ë‚˜ì´'])
            if age:
                all_ages = age

        # êµ¬ì§ìƒíƒœ ìˆ˜ì§‘
        if 'êµ¬ì§ìƒíƒœ' in df.columns and pd.notna(row['êµ¬ì§ìƒíƒœ']):
            status = str(row['êµ¬ì§ìƒíƒœ']).strip()
            if status and status not in all_job_status:
                all_job_status.append(status)

        # ì¤‘ë¶„ë¥˜ ì§ë¬´ë“¤ ìˆ˜ì§‘ (ì¤‘ë¶„ë¥˜ ì»¬ëŸ¼ë¶€í„° Unnamed ì»¬ëŸ¼ë“¤ê¹Œì§€)
        start_collecting = False
        for col in df.columns:
            if col == 'ì¤‘ë¶„ë¥˜':
                start_collecting = True

            if start_collecting and pd.notna(row[col]):
                job = str(row[col]).strip()
                if job:
                    all_job_names.append(job)

    if not all_job_names:
        print("âš ï¸  ì§ë¬´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

    # ì¤‘ë³µ ì œê±°
    all_areas = list(set(all_areas)) if all_areas else None
    all_education = all_education if all_education else None
    all_job_status = all_job_status if all_job_status else None

    # í•˜ë‚˜ì˜ í†µí•© config ìƒì„±
    config = {
        'categories': categories,  # ëª¨ë“  ëŒ€ë¶„ë¥˜
        'job_names': all_job_names,  # ëª¨ë“  ì§ë¬´
        'areas': all_areas,
        'education': all_education,
        'ages': all_ages if all_ages else None,
        'genders': None,  # ì´ ì‹œíŠ¸ì—ëŠ” ì„±ë³„ ì»¬ëŸ¼ ì—†ìŒ
        'job_status': all_job_status,
    }

    return config


def run_from_excel(
    excel_path: str = "configs/jobkorea_Excel.xlsx",
    sheet_name: str = "ê²€ìƒ‰ì¡°ê±´",
    start_page: int = 1,
    end_page: int = 1,
    page_size: int = 100,
    delay: float = 1.0,
    output_dir: str = "output"
):
    """
    jobkorea_Excel.xlsx íŒŒì¼ì—ì„œ ì„¤ì •ì„ ì½ì–´ì„œ ì‹¤í–‰

    Args:
        excel_path: ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
        sheet_name: ì‹œíŠ¸ëª… (ê¸°ë³¸: "ê²€ìƒ‰ì¡°ê±´")
        start_page: ì‹œì‘ í˜ì´ì§€
        end_page: ë í˜ì´ì§€
        page_size: í˜ì´ì§€ë‹¹ í¬ê¸°
        delay: ì§€ì—° ì‹œê°„(ì´ˆ)
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
    """
    # ì—‘ì…€ íŒŒì¼ í™•ì¸
    if not Path(excel_path).exists():
        print(f"âŒ ì—‘ì…€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {excel_path}")
        return

    # ì„¤ì • ë¡œë“œ (ëª¨ë“  í–‰ì„ í•˜ë‚˜ì˜ ê²€ìƒ‰ ì¡°ê±´ìœ¼ë¡œ í†µí•©)
    search_config = load_configs_from_excel(excel_path, sheet_name)

    if not search_config:
        print("âš ï¸  ê²€ìƒ‰ ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"\n{'='*60}")
    print(f"ğŸ“‹ ì—‘ì…€ ì„¤ì • íŒŒì¼: {excel_path}")
    print(f"ğŸ“„ ì‹œíŠ¸: {sheet_name}")
    print(f"{'='*60}\n")

    print(f"ğŸ” ê²€ìƒ‰ ì¡°ê±´:")
    print(f"   ëŒ€ë¶„ë¥˜: {', '.join(search_config['categories'])}")
    print(f"   ì§ë¬´: {', '.join(search_config['job_names'][:5])}{'...' if len(search_config['job_names']) > 5 else ''} (ì´ {len(search_config['job_names'])}ê°œ)")
    print(f"   ì§€ì—­: {search_config['areas']}")
    print(f"   í•™ë ¥: {search_config['education']}")
    print(f"   ë‚˜ì´: {search_config['ages']}")
    print(f"   êµ¬ì§ìƒíƒœ: {search_config['job_status']}")
    print(f"   í˜ì´ì§€: {start_page} ~ {end_page} (í¬ê¸°: {page_size})")
    print(f"{'='*60}\n")

    # ìŠ¤í¬ë˜í¼ ì´ˆê¸°í™”
    config = JobKoreaConfig()
    payload_manager = PayloadManager("data/payload_template.json")
    scraper = JobKoreaScraper(
        config=config,
        payload_manager=payload_manager,
        output_dir=output_dir
    )

    # ë°ì´í„° ìˆ˜ì§‘
    people = scraper.scrape(
        start_page=start_page,
        end_page=end_page,
        page_size=page_size,
        delay=delay,
        job_name=search_config['job_names'],
        areas=search_config['areas'],
        education=search_config['education'],
        ages=search_config['ages'],
        genders=search_config['genders'],
        job_status=search_config['job_status']
    )

    # ê²°ê³¼ ì €ì¥
    if people:
        import json
        # íŒŒì¼ëª…: ì‹œíŠ¸ëª… ê¸°ë°˜
        safe_sheet_name = sheet_name.replace('@', '_').replace('.', '_')
        json_path = Path(output_dir) / f"{safe_sheet_name}_summary.json"
        excel_path = Path(output_dir) / f"{safe_sheet_name}_ê²°ê³¼.xlsx"

        # JSON ì €ì¥
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(people, f, ensure_ascii=False, indent=2)

        # ì—‘ì…€ ì €ì¥
        scraper.exporter.save(people, str(excel_path))

        print(f"\nâœ… ì™„ë£Œ: {len(people)}ëª… ìˆ˜ì§‘")
        print(f"   ğŸ“„ JSON: {json_path}")
        print(f"   ğŸ“Š Excel: {excel_path}")
    else:
        print(f"\nâš ï¸  ìˆ˜ì§‘ëœ ë°ì´í„° ì—†ìŒ")

    print(f"\n{'='*60}")
    print(f"ğŸ‰ ì™„ë£Œ!")
    print(f"{'='*60}\n")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ==================== ğŸ”§ ì‹¤í–‰ ì„¤ì • ====================

    EXCEL_PATH = "configs/jobkorea_Excel.xlsx"  # ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
    SHEET_NAME = "ê²€ìƒ‰ì¡°ê±´"  # ì‹œíŠ¸ëª…

    # í˜ì´ì§€ ì„¤ì •
    START_PAGE = 1
    END_PAGE = 1
    PAGE_SIZE = 100
    DELAY = 1.0

    OUTPUT_DIR = "output"

    # =====================================================

    run_from_excel(
        excel_path=EXCEL_PATH,
        sheet_name=SHEET_NAME,
        start_page=START_PAGE,
        end_page=END_PAGE,
        page_size=PAGE_SIZE,
        delay=DELAY,
        output_dir=OUTPUT_DIR
    )


if __name__ == "__main__":
    main()
