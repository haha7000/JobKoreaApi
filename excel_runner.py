"""ì—‘ì…€ ì„¤ì • íŒŒì¼ì„ ì½ì–´ì„œ ì‹¤í–‰í•˜ëŠ” ë©”ì¸ íŒŒì¼"""
import pandas as pd
from pathlib import Path
from src.config import JobKoreaConfig
from src.payload_manager import PayloadManager
from src.scraper import JobKoreaScraper


def parse_age(age_str):
    """ë‚˜ì´ ë¬¸ìì—´ íŒŒì‹±"""
    if pd.isna(age_str) or str(age_str).strip() == '':
        return None

    age_str = str(age_str).strip()

    # ë²”ìœ„: "26-35"
    if '-' in age_str:
        parts = age_str.split('-')
        return (int(parts[0]), int(parts[1]))

    # ë‹¨ì¼: "28"
    return int(age_str)

    
def parse_list(value_str):
    """ì½¤ë§ˆë¡œ êµ¬ë¶„ëœ ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    if pd.isna(value_str) or str(value_str).strip() == '':
        return None

    return [x.strip() for x in str(value_str).split(',') if x.strip()]


def load_configs_from_excel(excel_path: str, sheet_name: str):
    """ì—‘ì…€ì—ì„œ ê²€ìƒ‰ ì„¤ì • ë¡œë“œ"""
    df = pd.read_excel(excel_path, sheet_name=sheet_name)

    # ì²« ë²ˆì§¸ í–‰ ë°ì´í„° ì¶”ì¶œ
    if len(df) == 0:
        return None

    first_row = df.iloc[0]

    config = {
        'job_names': [],  # ëª¨ë“  í–‰ì˜ ì§ë¬´ë¥¼ ëª¨ìŒ
        'areas': parse_list(first_row['ì§€ì—­']) if 'ì§€ì—­' in df.columns and pd.notna(first_row['ì§€ì—­']) else None,
        'education': parse_list(first_row['í•™ë ¥']) if 'í•™ë ¥' in df.columns and pd.notna(first_row['í•™ë ¥']) else None,
        'ages': parse_age(first_row['ë‚˜ì´']) if 'ë‚˜ì´' in df.columns and pd.notna(first_row['ë‚˜ì´']) else None,
        'genders': parse_list(first_row['ì„±ë³„']) if 'ì„±ë³„' in df.columns and pd.notna(first_row['ì„±ë³„']) else None,
        'job_status': parse_list(first_row['êµ¬ì§ìƒíƒœ']) if 'êµ¬ì§ìƒíƒœ' in df.columns and pd.notna(first_row['êµ¬ì§ìƒíƒœ']) else None,
    }

    # ëª¨ë“  í–‰ì˜ ì§ë¬´ ìˆ˜ì§‘
    if 'ì§ë¬´' in df.columns:
        for idx, row in df.iterrows():
            if pd.notna(row['ì§ë¬´']):
                job = str(row['ì§ë¬´']).strip()
                if job:
                    config['job_names'].append(job)

    return config


def run_from_excel(
    excel_path: str = "configs/search_config.xlsx",
    sheet_name: str = None,
    start_page: int = 1,
    end_page: int = 1,
    page_size: int = 100,
    delay: float = 1.0,
    output_dir: str = "output"
):
    """
    ì—‘ì…€ íŒŒì¼ì—ì„œ ì„¤ì •ì„ ì½ì–´ì„œ ì‹¤í–‰

    Args:
        excel_path: ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
        sheet_name: ì‹œíŠ¸ëª… (ê³„ì •ëª…), Noneì´ë©´ ì²« ë²ˆì§¸ ì‹œíŠ¸
        start_page: ì‹œì‘ í˜ì´ì§€
        end_page: ë í˜ì´ì§€
        page_size: í˜ì´ì§€ë‹¹ í¬ê¸°
        delay: ì§€ì—° ì‹œê°„(ì´ˆ)
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
    """
    # ì—‘ì…€ íŒŒì¼ í™•ì¸
    if not Path(excel_path).exists():
        print(f"âŒ ì—‘ì…€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {excel_path}")
        return

    # ì‹œíŠ¸ëª…ì´ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ì‹œíŠ¸ ì‚¬ìš©
    if sheet_name is None:
        xl = pd.ExcelFile(excel_path)
        sheet_name = xl.sheet_names[0]
        print(f"â„¹ï¸  ì‹œíŠ¸ëª… ë¯¸ì§€ì • â†’ ì²« ë²ˆì§¸ ì‹œíŠ¸ ì‚¬ìš©: '{sheet_name}'")

    # ì„¤ì • ë¡œë“œ
    search_config = load_configs_from_excel(excel_path, sheet_name)

    if not search_config:
        print("âš ï¸  ê²€ìƒ‰ ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"\n{'='*60}")
    print(f"ğŸ“‹ ì—‘ì…€ ì„¤ì • íŒŒì¼: {excel_path}")
    print(f"ğŸ“„ ì‹œíŠ¸: {sheet_name}")
    print(f"{'='*60}\n")

    print(f"ğŸ” ê²€ìƒ‰ ì¡°ê±´:")
    print(f"   ì§ë¬´: {', '.join(search_config['job_names']) if search_config['job_names'] else 'payload_template.json ì‚¬ìš©'}")
    print(f"   ì§€ì—­: {search_config['areas']}")
    print(f"   í•™ë ¥: {search_config['education']}")
    print(f"   ë‚˜ì´: {search_config['ages']}")
    print(f"   ì„±ë³„: {search_config['genders']}")
    print(f"   êµ¬ì§ìƒíƒœ: {search_config['job_status']}")
    print(f"   í˜ì´ì§€: {start_page} ~ {end_page} (í¬ê¸°: {page_size})")
    print(f"{'='*60}\n")

    # ìŠ¤í¬ë˜í¼ ì´ˆê¸°í™”
    config = JobKoreaConfig()
    payload_manager = PayloadManager("data/payload_template.json")
    scraper = JobKoreaScraper(
        config=config,
        payload_manager=payload_manager,
        output_dir=output_dir
    )

    # ë°ì´í„° ìˆ˜ì§‘
    # ì§ë¬´ ë¦¬ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ì „ë‹¬ (PayloadManagerê°€ ì—¬ëŸ¬ ì§ë¬´ ì²˜ë¦¬)
    job_names = search_config['job_names'] if search_config['job_names'] else None

    people = scraper.scrape(
        start_page=start_page,
        end_page=end_page,
        page_size=page_size,
        delay=delay,
        job_name=job_names,  # â† ë¦¬ìŠ¤íŠ¸ë¡œ ì „ë‹¬
        areas=search_config['areas'],
        education=search_config['education'],
        ages=search_config['ages'],
        genders=search_config['genders'],
        job_status=search_config['job_status']
    )

    # ê²°ê³¼ ì €ì¥
    if people:
        # íŒŒì¼ëª… ìƒì„± (ì‹œíŠ¸ëª… ê¸°ë°˜)
        import json
        safe_sheet_name = sheet_name.replace('@', '_').replace('.', '_')
        json_path = Path(output_dir) / f"{safe_sheet_name}_summary.json"
        excel_path = Path(output_dir) / f"{safe_sheet_name}_ê²°ê³¼.xlsx"

        # JSON ì €ì¥
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(people, f, ensure_ascii=False, indent=2)

        # ì—‘ì…€ ì €ì¥
        scraper.exporter.save(people, str(excel_path))

        print(f"\nâœ… ì™„ë£Œ: {len(people)}ëª… ìˆ˜ì§‘")
        print(f"   ğŸ“„ JSON: {json_path}")
        print(f"   ğŸ“Š Excel: {excel_path}")
    else:
        print(f"\nâš ï¸  ìˆ˜ì§‘ëœ ë°ì´í„° ì—†ìŒ")

    print(f"\n{'='*60}")
    print(f"ğŸ‰ ì™„ë£Œ!")
    print(f"{'='*60}\n")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ==================== ğŸ”§ ì‹¤í–‰ ì„¤ì • ====================

    EXCEL_PATH = "configs/search_config.xlsx"  # ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
    SHEET_NAME = None  # ì‹œíŠ¸ëª… (Noneì´ë©´ ì²« ë²ˆì§¸ ì‹œíŠ¸)

    # í˜ì´ì§€ ì„¤ì •
    START_PAGE = 1
    END_PAGE = 1
    PAGE_SIZE = 100
    DELAY = 1.0

    OUTPUT_DIR = "output"

    # =====================================================

    run_from_excel(
        excel_path=EXCEL_PATH,
        sheet_name=SHEET_NAME,
        start_page=START_PAGE,
        end_page=END_PAGE,
        page_size=PAGE_SIZE,
        delay=DELAY,
        output_dir=OUTPUT_DIR
    )


if __name__ == "__main__":
    main()
